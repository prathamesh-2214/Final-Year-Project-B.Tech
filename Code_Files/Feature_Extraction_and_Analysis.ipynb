{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is contains following to compare reconstructed images using SVD At various values of K and original images : \n",
    "\n",
    "- Functions to extract various image quality metrics \n",
    "- Extracting Features like color, texture , shape and Save into a CSV File\n",
    "- Perform Analysis in Frequency domain\n",
    "- Calculate Image Quality Metrics at Various Level of Image Pixel Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import mahotas\n",
    "from skimage import feature\n",
    "import numpy as np\n",
    "import mahotas as mt\n",
    "from sewar.full_ref import mse, rmse, psnr, uqi, ssim, ergas, scc, rase, sam, msssim, vifp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "dataset = pd.read_csv(\"E:\\Final_Year_Project\\Implementation\\Image-Text-NN-SC-Detection\\Analysis\\HAM10000_metadata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map disease codes to human-readable lesion types\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma',\n",
    "    'nc': 'No_Skin_Cancer'\n",
    "}\n",
    "\n",
    "# Load your dataset from CSV file or any other source\n",
    "# Replace 'your_dataset.csv' with your actual dataset file path\n",
    "dataset = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Add a new column 'cell_type' by mapping 'dx' to human-readable lesion types\n",
    "dataset['cell_type'] = dataset['dx'].map(lesion_type_dict.get)\n",
    "\n",
    "# Convert 'cell_type' to categorical codes (integer labels)\n",
    "dataset['disease_label'] = pd.Categorical(dataset['cell_type']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directory paths\n",
    "base_skin_dir = os.path.join(\"..\", \"Data\")  # Replace with your original image directory\n",
    "rbase_skin_dir = os.path.join(\"350_Components_PCA_Data\")  # Replace with your reconstructed image directory\n",
    "\n",
    "# Create dictionaries mapping image IDs to file paths\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n",
    "\n",
    "rimageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                      for x in glob(os.path.join(rbase_skin_dir, '*.jpg'))}\n",
    "\n",
    "# Assuming 'dataset' is your existing DataFrame\n",
    "# Add columns for original and reconstructed image paths\n",
    "dataset['path_o'] = dataset['image_id'].map(imageid_path_dict.get)  # Path to original images\n",
    "dataset['path_r'] = dataset['image_id'].map(rimageid_path_dict.get)  # Path to reconstructed images\n",
    "\n",
    "# Function to load images, resize, and convert to numpy array\n",
    "def load_image(image_path, resize=(450, 300)):\n",
    "    return np.asarray(Image.open(image_path).resize(resize))\n",
    "\n",
    "# Load original images and reconstructed images into DataFrame\n",
    "dataset['image_o'] = dataset['path_o'].map(lambda x: load_image(x))\n",
    "dataset['image_r'] = dataset['path_r'].map(lambda x: load_image(x))\n",
    "\n",
    "# Parameterize image resize dimensions\n",
    "resize_dimensions = (450, 300)\n",
    "\n",
    "# Explanation of attributes:\n",
    "# - 'path_o': Path to original images\n",
    "# - 'path_r': Path to reconstructed images\n",
    "# - 'image_o': Numpy array of resized original images\n",
    "# - 'image_r': Numpy array of resized reconstructed images\n",
    "\n",
    "# Display dataset attributes for comparison\n",
    "print(\"Dataset attributes:\")\n",
    "print(dataset[['image_id', 'path_o', 'path_r']].head())\n",
    "\n",
    "# Provide instructions for comparing image quality metrics\n",
    "print(\"\\nInstructions for image quality comparison:\")\n",
    "print(f\"- Use 'image_o' and 'image_r' columns for loading original and reconstructed images.\")\n",
    "print(f\"- Adjust 'resize_dimensions' parameter as needed for different image sizes (currently set to {resize_dimensions}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_pixel_difference(image1, image2):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of pixels that differ between two images.\n",
    "\n",
    "    This function computes the absolute difference between two images, applies a threshold to highlight\n",
    "    areas of change, and calculates the percentage of pixels that are different.\n",
    "\n",
    "    Args:\n",
    "        image1 (np.ndarray): The first image represented as a NumPy array.\n",
    "        image2 (np.ndarray): The second image represented as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        float: The percentage of pixels that are different between the two images.\n",
    "    \"\"\"\n",
    "    # Compute the absolute difference between the images\n",
    "    diff_image = cv2.absdiff(image1, image2)\n",
    "\n",
    "    # Threshold the difference image to highlight the areas of change\n",
    "    threshold = 5\n",
    "    _, thresholded_diff = cv2.threshold(diff_image, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Calculate the percentage of pixels that are different\n",
    "    total_pixels = np.prod(image1.shape)\n",
    "    different_pixels = np.count_nonzero(thresholded_diff)\n",
    "    percentage_difference = (different_pixels / total_pixels) * 100\n",
    "    \n",
    "    return percentage_difference\n",
    "\n",
    "# Example usage:\n",
    "# percentage_difference = percentage_pixel_difference(image1, image2)\n",
    "# print(f\"Percentage of different pixels: {percentage_difference:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lbp_feature(image, numPoints=16, radius=4, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Calculate Local Binary Pattern (LBP) features for an image.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Input image in RGB format.\n",
    "        numPoints (int, optional): Number of points to consider in the LBP calculation. Default is 16.\n",
    "        radius (int, optional): Radius of the circle to consider in the LBP calculation. Default is 4.\n",
    "        eps (float, optional): Small value to avoid division by zero in histogram normalization. Default is 1e-7.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Normalized histogram of LBP features.\n",
    "    \"\"\"\n",
    "    gray = lambda rgb: np.dot(rgb[..., :3], [0.299, 0.587, 0.114])  # Convert RGB to grayscale\n",
    "    image = gray(image)\n",
    "    lbp = feature.local_binary_pattern(image, numPoints, radius, method=\"uniform\")\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, numPoints + 3), range=(0, numPoints + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + eps)  # Normalize histogram\n",
    "    return hist\n",
    "\n",
    "def haralick_features(image):\n",
    "    \"\"\"\n",
    "    Calculate Haralick texture features for an image.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Input image in grayscale format.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Mean of Haralick texture features across 4 types of adjacency.\n",
    "    \"\"\"\n",
    "    textures = mt.features.haralick(image)  # Calculate Haralick features\n",
    "    ht_mean = textures.mean(axis=0)  # Mean of Haralick features\n",
    "    return ht_mean\n",
    "\n",
    "def get_hu_moments(image):\n",
    "    \"\"\"\n",
    "    Calculate Hu moments for an image.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Input image in RGB format.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Hu moments of the image.\n",
    "    \"\"\"\n",
    "    gray = lambda rgb: np.dot(rgb[..., :3], [0.299, 0.587, 0.114])  # Convert RGB to grayscale\n",
    "    gray = gray(image)\n",
    "    return cv2.HuMoments(cv2.moments(gray)).flatten()\n",
    "\n",
    "def build_histogram(image, bins=256):\n",
    "    \"\"\"\n",
    "    Build a color histogram for an image.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Input image in BGR format.\n",
    "        bins (int, optional): Number of bins for the histogram. Default is 256.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Histograms for red, green, and blue channels.\n",
    "    \"\"\"\n",
    "    rgb_image = np.flip(image, 2)  # Convert BGR to RGB\n",
    "    image_vector = rgb_image.reshape(1, -1, 3)  # Reshape image to a vector\n",
    "    div = 256 / bins  # Calculate division factor\n",
    "    bins_vector = (image_vector / div).astype(int)  # Quantize colors into bins\n",
    "    red = bins_vector[0, :, 0]\n",
    "    green = bins_vector[0, :, 1]\n",
    "    blue = bins_vector[0, :, 2]\n",
    "    return red, green, blue\n",
    "\n",
    "def mse(image1, image2):\n",
    "    \"\"\"\n",
    "    Calculate Mean Squared Error (MSE) between two images.\n",
    "\n",
    "    Args:\n",
    "        image1 (np.ndarray): First input image.\n",
    "        image2 (np.ndarray): Second input image.\n",
    "\n",
    "    Returns:\n",
    "        float: MSE between the two images.\n",
    "    \"\"\"\n",
    "    return np.mean((image1 - image2) ** 2)\n",
    "\n",
    "def custom_rmse(image1, image2):\n",
    "    \"\"\"\n",
    "    Calculate Root Mean Squared Error (RMSE) between two images.\n",
    "\n",
    "    Args:\n",
    "        image1 (np.ndarray): First input image.\n",
    "        image2 (np.ndarray): Second input image.\n",
    "\n",
    "    Returns:\n",
    "        float: RMSE between the two images.\n",
    "    \"\"\"\n",
    "    return np.sqrt(mse(image1, image2))\n",
    "\n",
    "def custom_psnr(image1, image2, max_value=255):\n",
    "    \"\"\"\n",
    "    Calculate Peak Signal-to-Noise Ratio (PSNR) between two images.\n",
    "\n",
    "    Args:\n",
    "        image1 (np.ndarray): First input image.\n",
    "        image2 (np.ndarray): Second input image.\n",
    "        max_value (int, optional): Maximum possible pixel value of the images. Default is 255.\n",
    "\n",
    "    Returns:\n",
    "        float: PSNR between the two images.\n",
    "    \"\"\"\n",
    "    mse_value = mse(image1, image2)\n",
    "    if mse_value == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(max_value / np.sqrt(mse_value))\n",
    "\n",
    "def custom_ssim(image1, image2):\n",
    "    \"\"\"\n",
    "    Calculate Structural Similarity Index (SSIM) between two images.\n",
    "\n",
    "    Args:\n",
    "        image1 (np.ndarray): First input image.\n",
    "        image2 (np.ndarray): Second input image.\n",
    "\n",
    "    Returns:\n",
    "        float: SSIM between the two images.\n",
    "    \"\"\"\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    L = 255  # Maximum value of pixels\n",
    "    C1 = (K1 * L) ** 2\n",
    "    C2 = (K2 * L) ** 2\n",
    "    mu1 = np.mean(image1)\n",
    "    mu2 = np.mean(image2)\n",
    "    sigma1_sq = np.var(image1)\n",
    "    sigma2_sq = np.var(image2)\n",
    "    sigma12 = np.cov(image1.flatten(), image2.flatten())[0, 1]\n",
    "    numerator = (2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)\n",
    "    denominator = (mu1 ** 2 + mu2 ** 2 + C1) * (sigma1_sq + sigma2_sq + C2)\n",
    "    return numerator / denominator\n",
    "\n",
    "def histogram_intersection(hist1, hist2):\n",
    "    \"\"\"\n",
    "    Compute the histogram intersection between two histograms.\n",
    "\n",
    "    Args:\n",
    "        hist1 (np.ndarray): First histogram.\n",
    "        hist2 (np.ndarray): Second histogram.\n",
    "\n",
    "    Returns:\n",
    "        float: Histogram intersection value.\n",
    "    \"\"\"\n",
    "    minima = np.minimum(hist1, hist2)\n",
    "    intersection = np.true_divide(np.sum(minima), np.sum(hist1))\n",
    "    return intersection\n",
    "\n",
    "def histogram_correlation(hist1, hist2):\n",
    "    \"\"\"\n",
    "    Compute the correlation coefficient between two histograms.\n",
    "\n",
    "    Args:\n",
    "        hist1 (np.ndarray): First histogram.\n",
    "        hist2 (np.ndarray): Second histogram.\n",
    "\n",
    "    Returns:\n",
    "        float: Correlation coefficient.\n",
    "    \"\"\"\n",
    "    mean1 = np.mean(hist1)\n",
    "    mean2 = np.mean(hist2)\n",
    "    std1 = np.std(hist1)\n",
    "    std2 = np.std(hist2)\n",
    "    correlation = np.mean((hist1 - mean1) * (hist2 - mean2)) / (std1 * std2)\n",
    "    return correlation\n",
    "\n",
    "def histogram_chi_square(hist1, hist2):\n",
    "    \"\"\"\n",
    "    Compute the Chi-Square distance between two histograms.\n",
    "\n",
    "    Args:\n",
    "        hist1 (np.ndarray): First histogram.\n",
    "        hist2 (np.ndarray): Second histogram.\n",
    "\n",
    "    Returns:\n",
    "        float: Chi-Square distance.\n",
    "    \"\"\"\n",
    "    chi_square = np.sum(np.square(hist1 - hist2) / (hist1 + hist2 + 1e-10))\n",
    "    return chi_square\n",
    "\n",
    "def histogram_bhattacharyya(hist1, hist2):\n",
    "    \"\"\"\n",
    "    Compute the Bhattacharyya distance between two histograms.\n",
    "\n",
    "    Args:\n",
    "        hist1 (np.ndarray): First histogram.\n",
    "        hist2 (np.ndarray): Second histogram.\n",
    "\n",
    "    Returns:\n",
    "        float: Bhattacharyya distance.\n",
    "    \"\"\"\n",
    "    hist1_normalized = hist1 / np.sum(hist1)\n",
    "    hist2_normalized = hist2 / np.sum(hist2)\n",
    "    bhattacharyya = -np.log(np.sum(np.sqrt(hist1_normalized * hist2_normalized)))\n",
    "    return bhattacharyya\n",
    "\n",
    "def euclidean_distance(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two vectors.\n",
    "\n",
    "    Args:\n",
    "        vector1 (np.ndarray): First vector.\n",
    "        vector2 (np.ndarray): Second vector.\n",
    "\n",
    "    Returns:\n",
    "        float: Euclidean distance between the two vectors.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(vector1 - vector2)\n",
    "\n",
    "def manhattan_distance(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two vectors.\n",
    "\n",
    "    Args:\n",
    "        vector1 (np.ndarray): First vector.\n",
    "        vector2 (np.ndarray): Second vector.\n",
    "\n",
    "    Returns:\n",
    "        float: Manhattan distance between the two vectors.\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(vector1 - vector2))\n",
    "\n",
    "def normalized_euclidean_distance(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Compute the normalized Euclidean distance between two vectors.\n",
    "    \n",
    "    Parameters:\n",
    "    vector1 (array_like): First input vector.\n",
    "    vector2 (array_like): Second input vector.\n",
    "    \n",
    "    Returns:\n",
    "    float: Normalized Euclidean distance between the two vectors.\n",
    "    \"\"\"\n",
    "    # Convert input vectors to numpy arrays\n",
    "    vector1 = np.array(vector1)\n",
    "    vector2 = np.array(vector2)\n",
    "    \n",
    "    # Normalize the input vectors\n",
    "    vector1_norm = vector1 / np.linalg.norm(vector1)\n",
    "    vector2_norm = vector2 / np.linalg.norm(vector2)\n",
    "    \n",
    "    # Compute the Euclidean distance between the normalized vectors\n",
    "    euclidean_distance = np.linalg.norm(vector1_norm - vector2_norm)\n",
    "    \n",
    "    return euclidean_distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcuating Percentage Pixel Difference at various Values of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the image quality metrics\n",
    "# Run this Code for every value of K you want to analyse reconstruction metrics for provided \n",
    "# reconstructed images at that k value exist\n",
    "\n",
    "k = 100 # Number of singular values used in construction\n",
    "distances_df = pd.DataFrame(columns=['Image_ID', f'%_pixel_diff_{k}'])\n",
    "\n",
    "# To keep track of image number we are on\n",
    "i = 0\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Iterate Over all rows in dataset\n",
    "for index, row in dataset.iterrows():\n",
    "    print(f\"For image {i} ... \")\n",
    "    image1 = row['image_o']\n",
    "    image2 = row['image_r']\n",
    "    \n",
    "    d = percentage_pixel_difference(image1, image2)\n",
    "    \n",
    "    \n",
    "    # Append distances to DataFrame\n",
    "    distances_df = distances_df.append({\n",
    "        'Image_ID': row['image_id'],\n",
    "        '%_pixel_diff': d\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    i+=1\n",
    "# Save the distances DataFrame as a CSV file\n",
    "distances_df.to_csv(f'percentage_pixel_all_images_difference_{k}_Components.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Texture Information for Original and reconstructed Dataset - Euclidean Distance Haralick Texture Features, Local Binary Pattern Histogram Intersection and Bhattacharya distance for LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the image quality metrics\n",
    "# Create an empty DataFrame to store the image quality metrics\n",
    "distances_df = pd.DataFrame(columns=['Image_ID', 'lbp_intersection',\n",
    "                                      'lbp_bhattacharya',\n",
    "                                      'haralick_euclidean'])\n",
    "\n",
    "# To keep track of image number we are on\n",
    "i = 0\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for index, row in dataset.iterrows():\n",
    "    print(f\"For image {i} ... \")\n",
    "    image1 = row['image_o']\n",
    "    image2 = row['image_r']\n",
    "    \n",
    "    # extract color hisograms\n",
    "    tlbp1, tharalick1 = lbp_feature(image1), haralick_features(image1)\n",
    "    tlbp2, tharalick2= lbp_feature(image2), haralick_features(image2)\n",
    "    \n",
    "    # Calculate Bhattacharyya distance for each component\n",
    "    lh = histogram_intersection(tlbp1,tlbp2)\n",
    "    lb = histogram_bhattacharyya(tlbp1,tlbp2)\n",
    "    he = np.linalg.norm(tharalick1 - tharalick2)\n",
    "    \n",
    "    # Append distances to DataFrame\n",
    "    distances_df = distances_df.append({\n",
    "        'Image_ID': row['image_id'],\n",
    "        'lbp_intersection': lh,\n",
    "        'lbp_bhattacharya': lb,\n",
    "        'haralick_euclidean': he\n",
    "        #'wavelet_correlation': we\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    i+=1\n",
    "# Save the distances DataFrame as a CSV file\n",
    "distances_df.to_csv(f'image_reconstruction_{k}_texture_Components_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Color Information - Bhattacharya Distance between reconstructed and original color histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep track of image number we are on\n",
    "i = 0\n",
    "for index, row in dataset.iterrows():\n",
    "    print(f\"For image {i} ... \")\n",
    "    image1 = row['image_o']\n",
    "    image2 = row['image_r']\n",
    "    \n",
    "    # Extract color histograms\n",
    "    hist_red1, hist_green1, hist_blue1 = build_histogram(image1)\n",
    "    hist_red2, hist_green2, hist_blue2 = build_histogram(image2)\n",
    "    \n",
    "    # Calculate Bhattacharyya distance for each color channel\n",
    "    blue_bhattacharyya_dist = histogram_bhattacharyya(hist_blue1, hist_blue2)\n",
    "    green_bhattacharyya_dist = histogram_bhattacharyya(hist_green1, hist_green2)\n",
    "    red_bhattacharyya_dist = histogram_bhattacharyya(hist_red1, hist_red2)\n",
    "    \n",
    "    # Append distances to DataFrame\n",
    "    distances_df = distances_df.append({\n",
    "        'Image_ID': row['image_id'],\n",
    "        'blue_bhattacharyya_distance': blue_bhattacharyya_dist,\n",
    "        'green_bhattacharyya_distance': green_bhattacharyya_dist,\n",
    "        'red_bhattacharyya_distance': red_bhattacharyya_dist\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "# Save the distances DataFrame as a CSV file\n",
    "distances_df.to_csv(f'image_reconstruction_{k}_color_Components_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting and Calculating euclidean distance and correlation between Hu Moments of reocnstructed and original images for Shape Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the image quality metrics\n",
    "distances_df = pd.DataFrame(columns=['Image_ID', 'correlation_coefficient', 'euclidean_distance'])\n",
    "\n",
    "# Iterate over every row and print it\n",
    "i = 0\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for index, row in dataset.iterrows():\n",
    "    print(f\"For image {i} ... \")\n",
    "    image1 = row['image_o']\n",
    "    image2 = row['image_r']\n",
    "    \n",
    "    # extract hu moments\n",
    "    hm1 = get_hu_moments(dataset,image1)\n",
    "    hm2 = get_hu_moments(dataset, image2)\n",
    "    \n",
    "    # get hu moments\n",
    "    cc = histogram_correlation(hm1, hm2)\n",
    "    ed = euclidean_distance(hm1,hm2)\n",
    "    \n",
    "    distances_df = distances_df.append({\n",
    "        'Image_ID': row['image_id'],\n",
    "        'correlation_coefficient': cc,\n",
    "        'euclidean_distance': ed\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    i+=1\n",
    "# Save the distances DataFrame as a CSV file\n",
    "distances_df.to_csv(f'image_reconstruction_{k}_shape_Components_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Quality Metrics at K values - PSNR, RMSE, SSIM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the image quality metrics\n",
    "image_ids = []\n",
    "rmse_values = []\n",
    "psnr_values = []\n",
    "ssim_values = []\n",
    "\n",
    "\n",
    "# Iterate over the rows in the dataset\n",
    "number = 0\n",
    "for i, row in enumerate(dataset.itertuples(), 1):\n",
    "    image1 = row.image_o\n",
    "    image2 = row.image_r\n",
    "    print(f\"for image {number}\")\n",
    "\n",
    "    # Convert images to YCbCr color space\n",
    "    image1_yuv = rgb2ycbcr(image1)\n",
    "    image2_yuv = rgb2ycbcr(image2)\n",
    "    \n",
    "    # Extract the luminance channel (Y)\n",
    "    image1_y = image1_yuv[:, :, 0]\n",
    "    image2_y = image2_yuv[:, :, 0]\n",
    "    \n",
    "    # Calculate image quality metrics\n",
    "    rmse_value = custom_rmse(image1, image2)\n",
    "    psnr_value = custom_psnr(image1, image2)\n",
    "    ssim_value = custom_ssim(image1_y, image2_y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Append values to lists\n",
    "    image_ids.append(row.image_id)\n",
    "    rmse_values.append(rmse_value)\n",
    "    psnr_values.append(psnr_value)\n",
    "    ssim_values.append(ssim_value)\n",
    "    \n",
    "\n",
    "    number += 1\n",
    "\n",
    "# Create a DataFrame with the collected metrics\n",
    "distances_df = pd.DataFrame({\n",
    "    'Image_ID': image_ids,\n",
    "    'RMSE': rmse_values,\n",
    "    'PSNR': psnr_values,\n",
    "    'SSIM': ssim_values,\n",
    "    \n",
    "})\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "distances_df.to_csv(f'image_reconstruction_metrics_{k}_Components_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Explained Ratio for K Singular Values used in reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import MiniBatchSparsePCA\n",
    "def pca_ratio(image, n_components):\n",
    "    \"\"\"\n",
    "    Applies PCA to the color channels of an image and returns the explained variance ratio for each channel.\n",
    "\n",
    "    Parameters:\n",
    "        image (numpy.ndarray): The input image.\n",
    "        n_components (int): Number of principal components to keep.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the explained variance ratios for the red, green, and blue channels.\n",
    "    \"\"\"\n",
    "    # Split the image into its blue, green, and red components\n",
    "    blue, green, red = cv2.split(image)\n",
    "    \n",
    "    # Initialize PCA for each color channel\n",
    "    pca_b = PCA(n_components, svd_solver='full')\n",
    "    pca_g = PCA(n_components, svd_solver='full')\n",
    "    pca_r = PCA(n_components, svd_solver='full')\n",
    "    \n",
    "    # Apply PCA to each channel and calculate the explained variance ratio\n",
    "    red_transformed = pca_r.fit_transform(red)\n",
    "    red_ratio = sum(pca_r.explained_variance_ratio_)\n",
    "    \n",
    "    green_transformed = pca_g.fit_transform(green)\n",
    "    green_ratio = sum(pca_g.explained_variance_ratio_)\n",
    "    \n",
    "    blue_transformed = pca_b.fit_transform(blue)\n",
    "    blue_ratio = sum(pca_b.explained_variance_ratio_)\n",
    "    \n",
    "    return [red_ratio, green_ratio, blue_ratio]\n",
    "\n",
    "# Create an empty DataFrame to store the image quality metrics\n",
    "distances_df = pd.DataFrame(columns=['Image_ID', 'ratio_red', 'ratio_green', 'ratio_blue'])\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Iterate over every row in the dataset\n",
    "i = 0\n",
    "for index, row in dataset.iterrows():\n",
    "    print(f\"For image {i} ... \")\n",
    "    image1 = row['image_o']\n",
    "    \n",
    "    # Apply PCA and get the explained variance ratios for the image\n",
    "    p = pca_ratio(image1, 200)\n",
    "    \n",
    "    # Append the results to the DataFrame\n",
    "    distances_df = distances_df.append({\n",
    "        'Image_ID': row['image_id'],\n",
    "        'ratio_red': p[0],\n",
    "        'ratio_green': p[1],\n",
    "        'ratio_blue': p[2]\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "# Save the distances DataFrame as a CSV file\n",
    "k = 100 # change value of k to calculate for different number of singular values\n",
    "distances_df.to_csv('SVD_{k}_shape_Components_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Metrics - Like Variety of Information and Normalized Mutual Information at various values of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import variation_of_information, normalized_mutual_information\n",
    "import pandas as pd\n",
    "\n",
    "# Create lists to store the image quality metrics\n",
    "image_ids = []\n",
    "normalized_mutual_info_scores = []\n",
    "voi_scores = []\n",
    "\n",
    "# Keep track of the row number\n",
    "number = 0\n",
    "\n",
    "# Iterate over rows in the dataset\n",
    "for i, row in enumerate(dataset.itertuples(), 1):\n",
    "    image1 = row.image_o  # Original image\n",
    "    image2 = row.image_r  # Reconstructed image\n",
    "    print(f\"Processing image {number} ...\")\n",
    "   \n",
    "    # Calculate Variation of Information (VOI) between the original and reconstructed images\n",
    "    voi = variation_of_information(image1, image2)\n",
    "    \n",
    "    # Calculate Normalized Mutual Information (NMI) between the original and reconstructed images\n",
    "    nmi = normalized_mutual_information(image1, image2)\n",
    "    \n",
    "    # Append values to respective lists\n",
    "    image_ids.append(row.image_id)\n",
    "    normalized_mutual_info_scores.append(nmi)\n",
    "    voi_scores.append(voi)\n",
    "\n",
    "    number += 1\n",
    "\n",
    "# Create a DataFrame to store the collected metrics\n",
    "distances_df = pd.DataFrame({\n",
    "    'Image_ID': image_ids,\n",
    "    'normalized_mutual_information': normalized_mutual_info_scores,\n",
    "    'VOI': voi_scores\n",
    "})\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "distances_df.to_csv(f'image_reconstruction_additional_metrics_{k}_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Features in Frequency Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def spectral_loss(image1, image2):\n",
    "    # Convert images to grayscale\n",
    "    image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the Fourier Transform\n",
    "    fft_image1 = np.fft.fft2(image1_gray)\n",
    "    fft_image2 = np.fft.fft2(image2_gray)\n",
    "\n",
    "    # Shift the zero-frequency component to the center\n",
    "    fft_shifted_image1 = np.fft.fftshift(fft_image1)\n",
    "    fft_shifted_image2 = np.fft.fftshift(fft_image2)\n",
    "\n",
    "    # Compute the magnitude spectra\n",
    "    magnitude_spectrum_image1 = np.log(np.abs(fft_shifted_image1) + 1)\n",
    "    magnitude_spectrum_image2 = np.log(np.abs(fft_shifted_image2) + 1)\n",
    "\n",
    "    # Compute the spectral loss\n",
    "    spectral_loss = np.mean(np.abs(magnitude_spectrum_image1 - magnitude_spectrum_image2))\n",
    "\n",
    "    return spectral_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def spectral_loss_coeff(image1, image2):\n",
    "    # Convert images to grayscale\n",
    "    image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the Fourier Transform\n",
    "    fft_image1 = np.fft.fft2(image1_gray)\n",
    "    fft_image2 = np.fft.fft2(image2_gray)\n",
    "\n",
    "    # Compute the magnitudes of the Fourier coefficients\n",
    "    magnitude_fft_image1 = np.abs(fft_image1)\n",
    "    magnitude_fft_image2 = np.abs(fft_image2)\n",
    "\n",
    "    # Compute the spectral loss\n",
    "    spectral_loss = np.mean(np.abs(magnitude_fft_image1 - magnitude_fft_image2))\n",
    "\n",
    "    return spectral_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_frequency_components(image1, image2):\n",
    "    # Load images\n",
    "    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    imag1 = image1\n",
    "    # Compute the Discrete Fourier Transform (DFT) for both images\n",
    "    dft1 = np.fft.fft2(image1)\n",
    "    dft2 = np.fft.fft2(image2)\n",
    "    \n",
    "    # Shift the zero-frequency component\n",
    "    dft_shifted1 = np.fft.fftshift(dft1)\n",
    "    dft_shifted2 = np.fft.fftshift(dft2)\n",
    "    \n",
    "    # Compute the Magnitude Spectrum for both images\n",
    "    magnitude_spectrum1 = np.abs(dft_shifted1)\n",
    "    magnitude_spectrum2 = np.abs(dft_shifted2)\n",
    "    # Flatten the magnitude spectra to 1D arrays\n",
    "    mag_spec1_flat = magnitude_spectrum1.flatten()\n",
    "    mag_spec2_flat = magnitude_spectrum2.flatten()\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation_matrix = np.corrcoef(mag_spec1_flat, mag_spec2_flat)\n",
    "    correlation_coefficient = correlation_matrix[0, 1]\n",
    "    \n",
    "    \n",
    "    # Define the dimensions of the images\n",
    "    rows, cols = image1.shape\n",
    "    center_row, center_col = rows // 2, cols // 2\n",
    "    \n",
    "    # Define the high-pass and low-pass filters\n",
    "    high_pass_filter = np.ones((rows, cols), np.uint8)\n",
    "    high_pass_filter[center_row - 30:center_row + 30, center_col - 30:center_col + 30] = 0\n",
    "    low_pass_filter = np.zeros((rows, cols), np.uint8)\n",
    "    low_pass_filter[center_row - 30:center_row + 30, center_col - 30:center_col + 30] = 1\n",
    "    \n",
    "    # Apply the filters to the magnitude spectra to obtain high-frequency and low-frequency components\n",
    "    high_frequency_spectrum1 = magnitude_spectrum1 * high_pass_filter\n",
    "    low_frequency_spectrum1 = magnitude_spectrum1 * low_pass_filter\n",
    "    high_frequency_spectrum2 = magnitude_spectrum2 * high_pass_filter\n",
    "    low_frequency_spectrum2 = magnitude_spectrum2 * low_pass_filter\n",
    "    # Calculate the correlation coefficient\n",
    "    correlation_matrix2 = np.corrcoef(high_frequency_spectrum1.flatten(), high_frequency_spectrum2.flatten())\n",
    "    correlation_coefficient2 = correlation_matrix2[0, 1]\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation_matrix1= np.corrcoef(low_frequency_spectrum1.flatten(), low_frequency_spectrum2.flatten())\n",
    "    correlation_coefficient1 = correlation_matrix1[0, 1]\n",
    "    # Compute Mean Squared Error (MSE) between high-frequency and low-frequency components\n",
    "    mse_high = np.mean(np.abs(high_frequency_spectrum1 - high_frequency_spectrum2))\n",
    "    mse_low = np.mean(np.abs(low_frequency_spectrum1 - low_frequency_spectrum2))\n",
    "    \n",
    "    return correlation_coefficient2,correlation_coefficient1, correlation_coefficient, mse_high, mse_low\n",
    "\n",
    "def plot_reconstructed_images(original_img):\n",
    "    # Compute Fourier Transform of the original image\n",
    "    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "    original_fft = np.fft.fft2(original_img)\n",
    "\n",
    "    # Shift the zero-frequency component to the center\n",
    "    original_fft_shifted = np.fft.fftshift(original_fft)\n",
    "\n",
    "    # Define the dimensions of the image\n",
    "    rows, cols = original_img.shape\n",
    "\n",
    "    # Create a high-pass filter to isolate high-frequency components\n",
    "    high_pass_filter = np.ones((rows, cols), np.uint8)\n",
    "    high_pass_filter[rows//2 - 30:rows//2 + 30, cols//2 - 30:cols//2 + 30] = 0\n",
    "\n",
    "    # Apply the high-pass filter to isolate high-frequency components\n",
    "    high_freq_fft_shifted = original_fft_shifted * high_pass_filter\n",
    "\n",
    "    # Reconstruct the image from high-frequency components\n",
    "    high_freq_reconstructed = np.fft.ifft2(np.fft.ifftshift(high_freq_fft_shifted)).real\n",
    "\n",
    "    # Create a low-pass filter to isolate low-frequency components\n",
    "    low_pass_filter = 1 - high_pass_filter\n",
    "\n",
    "    # Apply the low-pass filter to isolate low-frequency components\n",
    "    low_freq_fft_shifted = original_fft_shifted * low_pass_filter\n",
    "\n",
    "    # Reconstruct the image from low-frequency components\n",
    "    low_freq_reconstructed = np.fft.ifft2(np.fft.ifftshift(low_freq_fft_shifted)).real\n",
    "\n",
    "    # Plot the reconstructed images\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(high_freq_reconstructed, cmap='gray')\n",
    "    plt.title('Reconstructed Image from High-Frequency Components')\n",
    "    #plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(low_freq_reconstructed, cmap='gray')\n",
    "    plt.title('Reconstructed Image from Low-Frequency Components')\n",
    "    #plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize a list to collect results\n",
    "results = []\n",
    "components = 200 # number of singular values\n",
    "for index, row in dataset.iterrows():\n",
    "    print(f\"For image {index} ... \")\n",
    "    image1 = row['image_o']\n",
    "    image2 = row['image_r']\n",
    "    \n",
    "    #plot_reconstructed_images(image1)\n",
    "    #plot_reconstructed_images(image2)\n",
    "\n",
    "    # Example usage:\n",
    "    ccfh, ccfl, ccf, mse_high, mse_low = compare_frequency_components(image1, image2)\n",
    "    spectral_loss = spectral_loss_coeff(image1, image2)\n",
    "    \n",
    "    # Collect the results\n",
    "    result = {\n",
    "        \"Image Index\": index,\n",
    "        \"Spectral Loss Coeff\": spectral_loss,\n",
    "        \"Correlation Coeff\": ccf,\n",
    "        \"High Freq Corr Coeff\": ccfh,\n",
    "        \"Low Freq Corr Coeff\": ccfl,\n",
    "        \"MSE High-Frequency Component\": mse_high,\n",
    "        \"MSE Low-Frequency Component\": mse_low\n",
    "    }\n",
    "    \n",
    "    results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(f\"image_comparison_frequency_{components}_results.csv\", index=False)\n",
    "\n",
    "print(\"Results saved to image_comparison_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image resizing analysis at different Pixel Resolutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of sizes to resize the images\n",
    "sizes = [(450, 400), (450, 300), (300, 300), (450, 150), (200, 350), (300, 600), (256, 256), (200, 100), (400, 200)]\n",
    "\n",
    "for size in sizes:\n",
    "    # Resize images to the current size in the loop\n",
    "    print(\"Loading Image for size \", size)\n",
    "    dataset['image_o'] = dataset['path_o'].map(lambda x: np.asarray(Image.open(x).resize(size)))\n",
    "    dataset['image_r'] = dataset['path_r'].map(lambda x: np.asarray(Image.open(x).resize(size)))\n",
    "    \n",
    "    # Create lists to store the metrics\n",
    "    image_ids = []\n",
    "    rmse_values = []\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    hds = []\n",
    "    vois = []\n",
    "    ccf_values = []\n",
    "    ccfh_values = []\n",
    "    ccfl_values = []\n",
    "    mse_high_values = []\n",
    "    mse_low_values = []\n",
    "    spectral_loss_values = []\n",
    "\n",
    "    # Iterate over rows in the dataset\n",
    "    for number, row in enumerate(dataset.itertuples(), 1):\n",
    "        image1 = row.image_o\n",
    "        image2 = row.image_r\n",
    "        print(f\"Processing image {number}\")\n",
    "\n",
    "        # Convert images to YCbCr color space\n",
    "        image1_yuv = rgb2ycbcr(image1)\n",
    "        image2_yuv = rgb2ycbcr(image2)\n",
    "        \n",
    "        # Extract the luminance channel (Y)\n",
    "        image1_y = image1_yuv[:, :, 0]\n",
    "        image2_y = image2_yuv[:, :, 0]\n",
    "        \n",
    "        # Calculate image quality metrics\n",
    "        rmse_value = custom_rmse(image1, image2)  # Root Mean Square Error\n",
    "        psnr_value = custom_psnr(image1, image2)  # Peak Signal-to-Noise Ratio\n",
    "        ssim_value = custom_ssim(image1_y, image2_y)  # Structural Similarity Index\n",
    "        voi = variation_of_information(image1, image2)  # Variation of Information\n",
    "        hd = normalized_mutual_information(image1, image2)  # Normalized Mutual Information\n",
    "\n",
    "        # Calculate frequency comparison metrics\n",
    "        ccfh, ccfl, ccf, mse_high, mse_low = compare_frequency_components(image1, image2)\n",
    "        spectral_loss = spectral_loss_coeff(image1, image2)\n",
    "\n",
    "        # Append values to lists\n",
    "        image_ids.append(row.image_id)\n",
    "        rmse_values.append(rmse_value)\n",
    "        psnr_values.append(psnr_value)\n",
    "        ssim_values.append(ssim_value)\n",
    "        hds.append(hd)\n",
    "        vois.append(voi)\n",
    "        ccf_values.append(ccf)\n",
    "        ccfh_values.append(ccfh)\n",
    "        ccfl_values.append(ccfl)\n",
    "        mse_high_values.append(mse_high)\n",
    "        mse_low_values.append(mse_low)\n",
    "        spectral_loss_values.append(spectral_loss)\n",
    "\n",
    "    # Create a DataFrame to store the collected metrics\n",
    "    distances_df = pd.DataFrame({\n",
    "        'Image_ID': image_ids,\n",
    "        'RMSE': rmse_values,\n",
    "        'PSNR': psnr_values,\n",
    "        'SSIM': ssim_values,\n",
    "        'normalized_mutual_information': hds,\n",
    "        'VOI': vois,\n",
    "        'Correlation Coeff': ccf_values,\n",
    "        'High Freq Corr Coeff': ccfh_values,\n",
    "        'Low Freq Corr Coeff': ccfl_values,\n",
    "        'MSE High-Frequency Component': mse_high_values,\n",
    "        'MSE Low-Frequency Component': mse_low_values,\n",
    "        'Spectral Loss Coeff': spectral_loss_values\n",
    "    })\n",
    "\n",
    "    # Save the DataFrame as a CSV file\n",
    "    distances_df.to_csv(f\"Img_resizing_analysis/Image_resizing_information_additional_preservation_{size[0]}x{size[1]}_analysis.csv\", index=False)\n",
    "    print(f\"Results saved to Image_resizing_information_additional_preservation_{size[0]}x{size[1]}_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_csv_and_save_with_stats(input_csv):\n",
    "    # Read the input CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Describe the dataset to get statistics\n",
    "    stats_df = df.describe()\n",
    "    \n",
    "    # Generate the new filename\n",
    "    output_csv = input_csv.split('.csv')[0] + '_stats.csv'\n",
    "    \n",
    "    # Save the statistics DataFrame to a new CSV file\n",
    "    stats_df.to_csv(output_csv)\n",
    "    \n",
    "    print(f\"Statistics saved to {output_csv}\")\n",
    "import os\n",
    "# Example usage\n",
    "current_directory = \"Img_resizing_analysis/\"\n",
    "for filename in os.listdir(current_directory):\n",
    "    if \"New_Image_resizing_information_additional_preservation\" in filename and filename.endswith('.csv'):\n",
    "        input_csv = os.path.join(current_directory,filename)\n",
    "        analyze_csv_and_save_with_stats(input_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def extract_and_plot_means(directory):\n",
    "    # Dictionary to store mean values from each file\n",
    "    column_data = {}\n",
    "\n",
    "    # Iterate over files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if \"New_Image_resizing_information_additional_preservation\" in filename and \"stats\" in filename and filename.endswith('.csv'):\n",
    "            # Extract the string between \"(\" and \")\" in the filename\n",
    "            label = filename.split('_')[6]\n",
    "\n",
    "            # Read the CSV file and extract mean values\n",
    "            df = pd.read_csv(os.path.join(directory, filename), index_col=0)\n",
    "            mean_values = df.loc['mean']  # Get row with index 'mean'\n",
    "\n",
    "            # Store the mean values for each column\n",
    "            for column, value in mean_values.items():\n",
    "                if column not in column_data:\n",
    "                    column_data[column] = []\n",
    "                column_data[column].append((label, value))\n",
    "\n",
    "    # Determine the number of plots needed\n",
    "    num_plots = len(column_data)\n",
    "    num_figures = math.ceil(num_plots / 4)  # Each figure contains 4 subplots (2x2 grid)\n",
    "\n",
    "    # Plot mean values in separate figures\n",
    "    for fig_idx in range(num_figures):\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        subplot_labels = 'ABCD'\n",
    "\n",
    "        for subplot_idx in range(4):\n",
    "            column_idx = fig_idx * 4 + subplot_idx\n",
    "            if column_idx >= num_plots:\n",
    "                break\n",
    "            \n",
    "            column, data = list(column_data.items())[column_idx]\n",
    "            row = subplot_idx // 2\n",
    "            col = subplot_idx % 2\n",
    "\n",
    "            labels, means = zip(*data)\n",
    "            axs[row, col].plot(labels, means, color='red')\n",
    "            axs[row, col].set_xlabel('Image Size')\n",
    "            axs[row, col].set_ylabel('Mean Value')\n",
    "            axs[row, col].set_title(f' ({subplot_labels[subplot_idx]}): Image Resizing Comparison: {column}',pad=20)\n",
    "            axs[row, col].tick_params(axis='x', rotation=45)\n",
    "            axs[row, col].tick_params(axis='both', labelsize=10)\n",
    "            axs[row, col].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "current_directory = \"Img_resizing_analysis/\"\n",
    "extract_and_plot_means(current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def extract_and_plot_means(directory):\n",
    "    # Dictionary to store mean values from each file\n",
    "    column_data = {}\n",
    "\n",
    "    # Iterate over files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if \"New_Image_resizing_information_additional_preservation\" in filename and \"stats\" in filename and filename.endswith('.csv'):\n",
    "            # Extract the string between \"(\" and \")\" in the filename\n",
    "            label = filename.split('_')[6]\n",
    "\n",
    "            # Read the CSV file and extract mean values\n",
    "            df = pd.read_csv(os.path.join(directory, filename), index_col=0)\n",
    "            mean_values = df.loc['std']  # Get row with index 'mean'\n",
    "\n",
    "            # Store the mean values for each column\n",
    "            for column, value in mean_values.items():\n",
    "                if column not in column_data:\n",
    "                    column_data[column] = []\n",
    "                column_data[column].append((label, value))\n",
    "\n",
    "    # Determine the number of plots needed\n",
    "    num_plots = len(column_data)\n",
    "    num_figures = math.ceil(num_plots / 4)  # Each figure contains 4 subplots (2x2 grid)\n",
    "\n",
    "    # Plot mean values in separate figures\n",
    "    for fig_idx in range(num_figures):\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        subplot_labels = 'ABCD'\n",
    "\n",
    "        for subplot_idx in range(4):\n",
    "            column_idx = fig_idx * 4 + subplot_idx\n",
    "            if column_idx >= num_plots:\n",
    "                break\n",
    "            \n",
    "            column, data = list(column_data.items())[column_idx]\n",
    "            row = subplot_idx // 2\n",
    "            col = subplot_idx % 2\n",
    "\n",
    "            labels, means = zip(*data)\n",
    "            axs[row, col].plot(labels, means, color='blue')\n",
    "            axs[row, col].set_xlabel('Image Size')\n",
    "            axs[row, col].set_ylabel('Std Deviation Value')\n",
    "            axs[row, col].set_title(f' ({subplot_labels[subplot_idx]}): Image Resizing Comparison: {column}',pad=20)\n",
    "            axs[row, col].tick_params(axis='x', rotation=45)\n",
    "            axs[row, col].tick_params(axis='both', labelsize=10)\n",
    "            axs[row, col].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "current_directory = \"Img_resizing_analysis/\"\n",
    "extract_and_plot_means(current_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
