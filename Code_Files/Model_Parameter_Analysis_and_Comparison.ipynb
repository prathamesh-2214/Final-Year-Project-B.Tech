{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Studying the effect of Pruning Factor on Iteraitve Model Pruning for Proposed architectures using formula \n",
    "\n",
    "N_new = floor(N_old * (1 - Pruning_Factor))\n",
    "\n",
    "Where:\n",
    "- N_new: New number of filters/dense units after pruning\n",
    "- N_old: Old number of filters/dense units before pruning\n",
    "- Pruning_Factor: Pruning factor applied, expressed as a decimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    "    concatenate,\n",
    "    ZeroPadding2D\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_model_parameters(model):\n",
    "    \"\"\"\n",
    "    Count the total number of trainable parameters in a Keras model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model : tf.keras.Model\n",
    "        The Keras model for which parameters are to be counted.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    int\n",
    "        Total number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    return model.count_params()\n",
    "\n",
    "def reduce_filters(filters, factor):\n",
    "    \"\"\"\n",
    "    Reduce the number of filters in convolutional layers by a specified factor.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    filters : list\n",
    "        List of integers representing the number of filters in convolutional layers.\n",
    "    factor : float\n",
    "        Reduction factor for the number of filters.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list\n",
    "        Updated list of reduced filters.\n",
    "    \"\"\"\n",
    "    return [max(1, int(f * factor)) for f in filters]\n",
    "\n",
    "def reduce_dense_units(dense_units, factor):\n",
    "    \"\"\"\n",
    "    Reduce the number of units in dense layers by a specified factor.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dense_units : list\n",
    "        List of integers representing the number of units in dense layers.\n",
    "    factor : float\n",
    "        Reduction factor for the number of units.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list\n",
    "        Updated list of reduced dense units.\n",
    "    \"\"\"\n",
    "    return [max(1, int(u * factor)) for u in dense_units]\n",
    "\n",
    "def compute_parameters_for_architecture(build_model_fn, initial_filters, initial_dense_units, pruning_factor, num_reductions, output_csv, image_sizes=None, save_for_image_sizes=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute the number of parameters for different configurations of a given model architecture \n",
    "    and save the results to CSV file(s).\n",
    "    \n",
    "    This is stored in a csv file which can be analyse to study effects of change in model size and pruning in number of filters and \n",
    "    dense units when 1. Alll convolution layers and dense units of image model are reduce, if only one conv layer along with dense units of model is reduced etc.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    build_model_fn : function\n",
    "        Function to build the Keras model with specific parameters.\n",
    "    initial_filters : list\n",
    "        Initial values for the number of filters in convolutional layers.\n",
    "    initial_dense_units : list\n",
    "        Initial values for the number of units in dense layers.\n",
    "    pruning_factor : float\n",
    "        Factor by which to reduce filters and dense units in each iteration.\n",
    "    num_reductions : int\n",
    "        Number of reductions to apply.\n",
    "    output_csv : str\n",
    "        File path to save the CSV file(s) with computed parameters.\n",
    "    image_sizes : list of tuples, optional\n",
    "        List of tuples specifying different input image sizes (height, width, channels). Default is None.\n",
    "    save_for_image_sizes : bool, optional\n",
    "        Whether to save CSVs for each image size configuration. Default is False.\n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments for future extensibility.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if image_sizes is None:\n",
    "        image_sizes = []\n",
    "\n",
    "    configs = []\n",
    "    original_filters = initial_filters.copy()\n",
    "    original_dense_units = initial_dense_units.copy()\n",
    "\n",
    "    if image_sizes:\n",
    "        for image_size in image_sizes:\n",
    "            # Build model with the given image size\n",
    "            model = build_model_fn(original_filters, original_dense_units, input_shape=image_size)\n",
    "            num_params = count_model_parameters(model)\n",
    "            configs.append((image_size, original_filters, original_dense_units, num_params))\n",
    "            if save_for_image_sizes:\n",
    "                df = pd.DataFrame(configs, columns=['Image Size', 'Filters', 'Dense Units', 'Num Parameters'])\n",
    "                df.to_csv(f\"{output_csv}_image_size_pruning\", index=False)\n",
    "\n",
    "    # Build model with default input shape\n",
    "    model = build_model_fn(original_filters, original_dense_units)\n",
    "    num_params = count_model_parameters(model)\n",
    "    configs.append(('Default Input Shape', original_filters, original_dense_units, num_params))\n",
    "\n",
    "    for i in range(num_reductions + 1):\n",
    "        # Reduce all convolutional layers and dense layers\n",
    "        current_filters = reduce_filters(original_filters, pruning_factor**i)\n",
    "        current_dense_units = reduce_dense_units(original_dense_units, pruning_factor**i)\n",
    "        model = build_model_fn(current_filters, current_dense_units)\n",
    "        num_params = count_model_parameters(model)\n",
    "        configs.append((current_filters, current_dense_units, num_params, f'All Layers (Reduction {i})'))\n",
    "\n",
    "    # Reduce all conv layer, 1 conv layer, 2 conv layer or 3 conv layer...\n",
    "    for i in range(1, len(original_filters) + 1):\n",
    "        current_filters = original_filters.copy()\n",
    "        for j in range(num_reductions + 1):\n",
    "            temp_filters = current_filters.copy()\n",
    "            temp_filters[:i] = reduce_filters(original_filters[:i], pruning_factor**j)\n",
    "            temp_dense_units = reduce_dense_units(original_dense_units, pruning_factor**j)\n",
    "            model = build_model_fn(temp_filters, temp_dense_units)\n",
    "            num_params = count_model_parameters(model)\n",
    "            configs.append((temp_filters, temp_dense_units, num_params, f'First {i} Layer(s) (Reduction {j})'))\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    df = pd.DataFrame(configs, columns=['Filters', 'Dense Units', 'Num Parameters', 'Configuration'])\n",
    "    df.to_csv(f\"{output_csv}_parameter_reduction\", index=False)\n",
    "\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_example_net(num_filters, num_dense_units, input_shape=(200, 100, 3)):\n",
    "\n",
    "    text_model = Sequential()\n",
    "    text_model.add(Dense(4, input_dim=3, activation=\"relu\"))\n",
    "    text_model.add(BatchNormalization())\n",
    "    text_model.add(Dropout(0.25))\n",
    "\n",
    "    text_model.add(Dense(6, input_dim=3, activation=\"relu\"))\n",
    "    text_model.add(BatchNormalization())\n",
    "\n",
    "    text_model.add(Dense(2, input_dim=3, activation=\"relu\"))\n",
    "    text_model.add(BatchNormalization())\n",
    "    text_model.add(Dropout(0.25))\n",
    "\n",
    "    text_model.add(Dense(units=1, activation=\"relu\"))  # Adjust units for 7 classes\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(num_filters[0], (5, 5), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(num_filters[1], (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_dense_units[0], activation='relu'))\n",
    "    model.add(Dense(num_dense_units[1], activation='relu'))\n",
    "    combined_output = concatenate([text_model.output, model.output])\n",
    "\n",
    "    x = Dense(8, activation=\"relu\")(combined_output)\n",
    "    x = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model([text_model.input, model.input], x)\n",
    "\n",
    "    return model\n",
    "\n",
    "# EXAMPLE USAGE\n",
    "# This can be extended to any architecture given build model function is defined as per requirement and analysis just as it is defined above in build_example_net\n",
    "initial_filters = [6, 16]\n",
    "initial_dense_units = [84, 120]\n",
    "pruning_factor = 0.5\n",
    "num_reductions = 5\n",
    "output_csv = f'Lenet_{pruning_factor}_parameters.csv'\n",
    "image_sizes = [(200, 100, 3), (400, 200, 3)]\n",
    "\n",
    "compute_parameters_for_architecture(build_example_net, initial_filters, initial_dense_units, pruning_factor, num_reductions, output_csv, image_sizes=image_sizes, save_for_image_sizes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_parameters_from_csv(csv_file, title='Parameter vs Image Size', parameter_fontsize=12, title_fontsize=14):\n",
    "    \"\"\"\n",
    "    Plot number of learnable parameters against Image Size from a CSV file generated after 'compute_parameters_for_architecture' Func .\n",
    "\n",
    "    Parameters:\n",
    "    - csv_file (str): Path to the CSV file containing 'Image_Size' and 'Parameter' columns.\n",
    "    - title (str, optional): Title of the plot. Default is 'Parameter vs Image Size'.\n",
    "    - parameter_fontsize (int, optional): Font size for parameters. Default is 12.\n",
    "    - title_fontsize (int, optional): Font size for title. Default is 14.\n",
    "    \"\"\"\n",
    "    # Read CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Sort DataFrame by 'Num Parameters'\n",
    "    df_sorted = df.sort_values(by='Num Parameters',ascending=False)\n",
    "\n",
    "    # Extract sorted columns\n",
    "    image_sizes = df_sorted['Image Size']\n",
    "    parameters = df_sorted['Num Parameters']\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(7, 4.5))  # Adjust figsize as needed\n",
    "\n",
    "    # Plot parameters against image sizes\n",
    "    ax.plot(image_sizes, parameters, marker='o', linestyle='-', color='b', markersize=5)\n",
    "\n",
    "    # Set title and adjust fontsize\n",
    "    ax.set_title(title, fontsize=title_fontsize,pad=20)\n",
    "\n",
    "    # Labeling axes\n",
    "    ax.set_xlabel('Image Size', fontsize=12)\n",
    "    ax.set_ylabel('Parameter', fontsize=parameter_fontsize)\n",
    "\n",
    "    # Set x-axis ticks (optional depending on data)\n",
    "     # Set x-axis and y-axis tick label font sizes\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    # Rotate x-axis labels by 45 degrees\n",
    "    plt.xticks(rotation=45)\n",
    "    # Display grid\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Automatically adjust layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Change Input File as per requirement and modify parameters like title, fontsize \n",
    "csv_file = 'Custom_Cnn_2_input_shape_parameters.csv'  # Replace with your CSV file path\n",
    "\n",
    "plot_parameters_from_csv(csv_file, title='Custom Neural Network - 2 : #Parameters vs Image Size', parameter_fontsize=12, title_fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def plot_parameters_from_csv(csv_file, title='Num Parameters vs Image Size', parameter_fontsize=12, title_fontsize=14,\n",
    "                             xtick_fontsize=10, ytick_fontsize=10, legend_fontsize=10):\n",
    "    \"\"\"\n",
    "    Plot parameters against Reduction Number from a CSV file for each unique Configuration and determine trend type.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_file (str): Path to the CSV file containing 'Reduction Number', 'Configuration', and 'Num Parameters' columns.\n",
    "    - title (str, optional): Title of the plot. Default is 'Num Parameters vs Reduction Number'.\n",
    "    - parameter_fontsize (int, optional): Font size for parameters. Default is 12.\n",
    "    - title_fontsize (int, optional): Font size for title. Default is 14.\n",
    "    - xtick_fontsize (int, optional): Font size for x-axis tick labels. Default is 10.\n",
    "    - ytick_fontsize (int, optional): Font size for y-axis tick labels. Default is 10.\n",
    "    - legend_fontsize (int, optional): Font size for legend. Default is 10.\n",
    "    \"\"\"\n",
    "    # Read CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))  # Adjust figsize as needed\n",
    "\n",
    "    # Iterate over each unique configuration\n",
    "    Label = [\"All Conv Layers\", \"1 Conv Layer\", \"2 Conv Layers\", \"3 Conv Layers\"]\n",
    "    colors = ['b', 'g', 'r', 'c']\n",
    "    trend_types = []\n",
    "\n",
    "    for j, label in enumerate(Label):\n",
    "        # Filter data for current configuration\n",
    "        df_config = df[df['Configuration'] == label]\n",
    "\n",
    "        # Extract Reduction Number and Num Parameters\n",
    "        reduction_numbers = df_config['Reduction Number']\n",
    "        num_parameters = df_config['Num Parameters']\n",
    "\n",
    "        # Plot parameters against Reduction Number\n",
    "        ax.plot(reduction_numbers, num_parameters, marker='o', linestyle='-', markersize=5, label=f'{label}', color=colors[j])\n",
    "\n",
    "        # Perform linear regression to determine trend\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(reduction_numbers, num_parameters)\n",
    "\n",
    "        # Determine trend type based on R-squared value\n",
    "        if r_value ** 2 > 0.95:\n",
    "            trend_type = 'Exponential'\n",
    "        elif r_value ** 2 > 0.85:\n",
    "            trend_type = 'Polynomial'\n",
    "        else:\n",
    "            trend_type = 'Linear'\n",
    "\n",
    "        trend_types.append(trend_type)\n",
    "\n",
    "    # Set title and adjust fontsize\n",
    "    ax.set_title(title, fontsize=title_fontsize, pad=20)\n",
    "\n",
    "    # Labeling axes\n",
    "    ax.set_xlabel('Reduction Number', fontsize=parameter_fontsize)\n",
    "    ax.set_ylabel('Num Parameters', fontsize=parameter_fontsize)\n",
    "\n",
    "    # Set x-axis and y-axis tick label font sizes\n",
    "    ax.tick_params(axis='x', labelsize=xtick_fontsize)\n",
    "    ax.tick_params(axis='y', labelsize=ytick_fontsize)\n",
    "\n",
    "    # Display grid\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(fontsize=legend_fontsize)\n",
    "\n",
    "    # Automatically adjust layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    # Print trend types\n",
    "    for j, label in enumerate(Label):\n",
    "        print(f\"Trend type for {label}: {trend_types[j]}\")\n",
    "\n",
    "# Example usage:\n",
    "csv_file = 'Custom_Cnn_1_0.66_parameters.csv'  # Replace with your CSV file path\n",
    "\n",
    "plot_parameters_from_csv(csv_file, title='Custom Neural Network - Num Parameters vs Reduction Number',\n",
    "                         parameter_fontsize=12, title_fontsize=16,\n",
    "                         xtick_fontsize=12, ytick_fontsize=12, legend_fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
