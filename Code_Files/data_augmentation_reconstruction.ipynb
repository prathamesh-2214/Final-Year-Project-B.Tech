{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook contains the functions to \n",
    "\n",
    "- Perform Data Augmentation on Images for Oversampling and balancing Images\n",
    "- Generate Datasets at various values of k after SVD Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "\n",
    "def save_augmented_image(original_image_path, row_data, counter):\n",
    "    \"\"\"\n",
    "    Save augmented image and update row data with new image name.\n",
    "\n",
    "    Parameters:\n",
    "    - original_image_path (str): Path to the original image file.\n",
    "    - row_data (pd.Series): Row data containing image and metadata.\n",
    "    - counter (int): Counter to generate unique identifier for augmented image.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Series: Updated row data with new image ID.\n",
    "    \"\"\"\n",
    "    # Define augmentation parameters\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=(0.2, 0.7)\n",
    "    )\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = 'Original_Augmented'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Convert image to array and reshape for augmentation\n",
    "    img_array = row_data['image']\n",
    "    img_array = img_array.reshape((1,) + img_array.shape)\n",
    "\n",
    "    # Generate augmented image\n",
    "    aug_iter = datagen.flow(img_array, batch_size=1)\n",
    "    aug_image = next(aug_iter)[0].astype(np.uint8)\n",
    "\n",
    "    # Convert array back to image\n",
    "    aug_image = array_to_img(aug_image)\n",
    "\n",
    "    # Save the augmented image\n",
    "    new_image_name = f\"{row_data['image_id']}_{counter}_orgbcc_{row_data['cell_type']}_aug.png\"\n",
    "    aug_image.save(os.path.join(output_dir, new_image_name))\n",
    "\n",
    "    # Update row data with new image name\n",
    "    new_row = row_data.copy()\n",
    "    new_row['image_id'] = new_image_name\n",
    "    return new_row\n",
    "\n",
    "def augmentation_dataset(dataset, label):\n",
    "    \"\"\"\n",
    "    Perform data augmentation on a dataset for a specific label.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (pd.DataFrame): DataFrame containing image data and labels.\n",
    "    - label (str): Label of the class to augment in the dataset.\n",
    "\n",
    "    Saves:\n",
    "    - CSV file: Augmented dataset with updated image names.\n",
    "    \"\"\"\n",
    "    # Filter dataset by label\n",
    "    df = dataset[dataset['cell_type'] == label]\n",
    "\n",
    "    # Initialize output directory and image counter\n",
    "    output_dir = 'Original_Augmented'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_counter = 1\n",
    "\n",
    "    # List to store new DataFrame rows\n",
    "    new_rows = []\n",
    "\n",
    "    # Iterate through each image in the filtered DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Generate augmented images (in this case, only 1 augmentation per image)\n",
    "        # range(2) will generate 2 augmentations per image\n",
    "        for _ in range(1):\n",
    "            print(f\"Processing image {row['image_id']} iteration {_ + 1}\")\n",
    "            new_row = save_augmented_image(row['image'], row, image_counter)\n",
    "            new_rows.append(new_row)\n",
    "            image_counter += 1\n",
    "\n",
    "    # Create a new DataFrame from the list of new rows\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "    # Save the new DataFrame as a CSV file\n",
    "    new_df.to_csv(f\"Original_{label}_augmentation.csv\", index=False)\n",
    "\n",
    "# Example usage:\n",
    "class_list = [\"Basal cell carcinoma\"]  # List of classes to augment\n",
    "\n",
    "# Perform augmentation for each class in the class_list\n",
    "for label in class_list:\n",
    "    augmentation_dataset(dataset, label)\n",
    "\n",
    "print(\"Data augmentation complete and new DataFrame saved as CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_image(image, n_components):\n",
    "    \"\"\"\n",
    "    Perform PCA on image channels (Blue, Green, Red).\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): Input image as a NumPy array (BGR format).\n",
    "    - n_components (int): Number of principal components to retain.\n",
    "\n",
    "    Returns:\n",
    "    - transformed_channels (list of numpy.ndarray): Transformed PCA components for each channel.\n",
    "    - pca_solvers (list of PCA objects): List of PCA objects fitted to each channel.\n",
    "    \"\"\"\n",
    "    # Splitting channels\n",
    "    blue, green, red = cv2.split(image)\n",
    "\n",
    "    # Initialize PCA for each channel with specified number of components\n",
    "    pca_b = PCA(n_components, svd_solver='full')\n",
    "    pca_g = PCA(n_components, svd_solver='full')\n",
    "    pca_r = PCA(n_components, svd_solver='full')\n",
    "\n",
    "    # Applying PCA to each channel\n",
    "    blue_transformed = pca_b.fit_transform(blue)\n",
    "    green_transformed = pca_g.fit_transform(green)\n",
    "    red_transformed = pca_r.fit_transform(red)\n",
    "\n",
    "    # Return transformed components and PCA objects\n",
    "    return [red_transformed, green_transformed, blue_transformed], [pca_b, pca_g, pca_r]\n",
    "\n",
    "def reconstruct_pca_image(transformed_channels, pca_solvers):\n",
    "    \"\"\"\n",
    "    Reconstruct the original image from PCA-transformed components.\n",
    "\n",
    "    Parameters:\n",
    "    - transformed_channels (list of numpy.ndarray): Transformed PCA components for each channel.\n",
    "    - pca_solvers (list of PCA objects): List of PCA objects fitted to each channel.\n",
    "\n",
    "    Returns:\n",
    "    - reconstructed_image (numpy.ndarray): Reconstructed image from PCA components.\n",
    "    \"\"\"\n",
    "    # Inverse transform to reconstruct channels\n",
    "    red_inverted = pca_solvers[2].inverse_transform(transformed_channels[0])\n",
    "    green_inverted = pca_solvers[1].inverse_transform(transformed_channels[1])\n",
    "    blue_inverted = pca_solvers[0].inverse_transform(transformed_channels[2])\n",
    "\n",
    "    # Merge channels and convert to uint8 image\n",
    "    reconstructed_image = (cv2.merge((blue_inverted, green_inverted, red_inverted))).astype(np.uint8)\n",
    "\n",
    "    return reconstructed_image\n",
    "\n",
    "def save_images(df, save_path, image_column, components):\n",
    "    \"\"\"\n",
    "    Saves compressed images generated using PCA from a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'image_id' and 'image' columns.\n",
    "    - save_path (str): Path to the directory for saving images.\n",
    "    - image_column (str): Column name containing 3D image arrays.\n",
    "    - components (int): Number of PCA components to retain.\n",
    "\n",
    "    Saves:\n",
    "    - Compressed images with 'image_id' as file name in the specified directory.\n",
    "    \"\"\"\n",
    "    # Create the save directory if it doesn't exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # Iterate through DataFrame rows\n",
    "    for ind in df.index:\n",
    "        # Retrieve image array and image ID\n",
    "        image_array = df.loc[ind, image_column]\n",
    "        image_id = df.loc[ind, 'image_id']\n",
    "\n",
    "        # Perform PCA on the image\n",
    "        img_reduced_arr, pca_solver = pca_image(image_array, components)\n",
    "\n",
    "        # Reconstruct the image from PCA components\n",
    "        image_to_save = reconstruct_pca_image(img_reduced_arr, pca_solver)\n",
    "\n",
    "        # Generate unique image name with image_id\n",
    "        image_name = f\"{image_id}.jpg\"  # Use JPG format for simplicity, adjust as needed\n",
    "\n",
    "        # Construct full save path\n",
    "        full_path = os.path.join(save_path, image_name)\n",
    "\n",
    "        # Save the image using OpenCV\n",
    "        cv2.imwrite(full_path, cv2.cvtColor(image_to_save, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        print(f\"Image saved: {full_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'dataset' is your pandas DataFrame with 'image_id' and 'image' columns\n",
    "# Adjust '400_Components_PCA_Data' to your desired save path\n",
    "save_images(dataset, '400_Components_PCA_Data', 'image', components=400)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
